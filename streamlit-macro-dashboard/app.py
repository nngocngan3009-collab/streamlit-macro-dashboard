# =========================
# python7_fixed.py ‚Äî Data360 search (WB_WDI) + World Bank fetch
# - Search indicators qua Data360 (l·ªçc WB_WDI, chu·∫©n ID hi·ªÉn th·ªã)
# - B·∫£ng d·ªØ li·ªáu ƒë·∫ßu ra D·∫†NG R·ªòNG:
#   Year | Country | <Indicator Name 1> | <Indicator Name 2> | ...
# - B·∫£o ƒë·∫£m: ch·ªçn bao nhi√™u indicator ‚Üí c√≥ b·∫•y nhi√™u c·ªôt (k·ªÉ c·∫£ r·ªóng n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu)
# - T√≠nh nƒÉng: Bi·ªÉu ƒë·ªì, Heatmap, Th·ªëng k√™, CSV, AI (Gemini) nh∆∞ b·∫£n chu·∫©n
# =========================

import ssl, certifi
ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())

import os
import time
from typing import Dict, Any, Optional, List
import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.figure_factory as ff

# (tu·ª≥ ch·ªçn) AI insight
try:
    import google.generativeai as genai
except Exception:
    genai = None

# ---------------- Config ----------------
WB_BASE = "https://api.worldbank.org/v2"
DATA360_BASE_URL = os.environ.get("DATA360_BASE_URL", "https://api.data360.org")
D360_SEARCH_ENDPOINT = "/data360/searchv2"

HEADERS = {
    "User-Agent": "Streamlit-WB-Client/1.0",
    "Accept": "application/json",
    "Content-Type": "application/json",
}
REQ_TIMEOUT = 60
RETRIES = 4
BACKOFF = 1.6

DEFAULT_DATE_RANGE = (2004, 2024)

# ---------------- Retry helpers ----------------
def _sleep(attempt: int) -> float:
    return min(BACKOFF ** attempt, 12.0)

def http_get_json(url: str, params: Dict[str, Any]) -> Any:
    last_err = None
    for i in range(RETRIES + 1):
        try:
            r = requests.get(url, params=params, headers={"User-Agent": HEADERS["User-Agent"]}, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_sleep(i))
    raise RuntimeError(f"GET {url} failed after retries: {last_err}")

def data360_request_json(payload: Dict[str, Any]) -> Any:
    url = f"{DATA360_BASE_URL}{D360_SEARCH_ENDPOINT}"
    last_err = None
    for i in range(RETRIES + 1):
        try:
            r = requests.post(url, json=payload, headers=HEADERS, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_sleep(i))
    raise RuntimeError(f"POST {url} failed after retries: {last_err}")

# ---------------- Utilities ----------------
def _to_int(x, default=0):
    try:
        return int(x)
    except (TypeError, ValueError):
        return default

def _format_dot(code_underscore: str) -> str:
    """
    SP_POP_TOTL -> SP.POP.TOTL
    """
    return (code_underscore or "").strip("_").replace("_", ".")

def _cut_wb_id(full_id: str) -> str:
    """
    WB_WDI_SP_POP_TOTL -> SP_POP_TOTL
    (N·∫øu kh√¥ng ƒë√∫ng format th√¨ tr·∫£ nguy√™n)
    """
    s = full_id or ""
    return s[len("WB_WDI_"):] if s.startswith("WB_WDI_") else s

# ---------------- Country list ----------------
@st.cache_data(show_spinner=False, ttl=24*3600)
def wb_list_countries() -> pd.DataFrame:
    out, page = [], 1
    while True:
        js = http_get_json(f"{WB_BASE}/country", {"format":"json","per_page":400,"page":page})
        if not isinstance(js, list) or len(js) < 2:
            break
        meta, data = js
        per_page, total = _to_int(meta.get("per_page",0)), _to_int(meta.get("total",0))
        for c in data:
            # B·ªè nh√≥m kh√¥ng √°p d·ª•ng ("Aggregates": region id = "NA")
            if (c.get("region") or {}).get("id") != "NA":
                out.append({"code": c["id"], "name": c["name"]})
        if page * per_page >= total:
            break
        page += 1
    return pd.DataFrame(out).sort_values("name").reset_index(drop=True)

# ---------------- Indicator search (Data360 first, WB fallback) ----------------
@st.cache_data(show_spinner=False, ttl=6*3600)
def wb_indicator_catalog(keyword: str, max_pages: int = 2) -> pd.DataFrame:
    """
    Fallback: World Bank /indicator
    """
    results, page = [], 1
    key = (keyword or "").strip().lower()
    while page <= max_pages:
        js = http_get_json(f"{WB_BASE}/indicator", {"format":"json","per_page":5000,"page":page})
        if not isinstance(js, list) or len(js) < 2:
            break
        meta, data = js
        per_page, total = _to_int(meta.get("per_page",0)), _to_int(meta.get("total",0))
        for it in data:
            _id, _name = it.get("id",""), it.get("name","")
            if key and (key not in _name.lower() and key not in _id.lower()):
                continue
            results.append({"id": _id, "name": _name})
        if page * per_page >= total:
            break
        page += 1
    df = pd.DataFrame(results).drop_duplicates(subset=["id"]).sort_values("name").reset_index(drop=True)
    # Chu·∫©n c·ªôt ƒë·ªÉ ƒë·ªìng nh·∫•t v·ªõi Data360 schema hi·ªÉn th·ªã
    if df.empty:
        return pd.DataFrame(columns=["display_code","name","full_id","wb_id"])
    df["display_code"] = df["id"]         # ƒë√£ l√† dot format
    df["full_id"] = df["id"]
    df["wb_id"] = "WB_WDI"
    return df[["display_code","name","wb_id","full_id"]]

@st.cache_data(show_spinner=False, ttl=6*3600)
def data360_search_indicators(keyword: str, top: int = 40) -> pd.DataFrame:
    """
    Search indicators via Data360 searchv2, filter only WB_WDI.
    Chu·∫©n ho√° hi·ªÉn th·ªã 'display_code' d·∫°ng SP.POP.TOTL / NY.GDP.MKTP.CD.
    Lo·∫°i b·ªè c√°c k·∫øt qu·∫£ ki·ªÉu '6.0.GDP_usd' b·∫±ng c√°ch:
      - ch·ªâ gi·ªØ record c√≥ series_description/database_id == 'WB_WDI'
      - l·∫•y short_id t·ª´ full_id 'WB_WDI_SP_POP_TOTL' r·ªìi format dot.
    """
    payload = {
        "count": False,
        "search": (keyword or "").strip(),
        "select": "series_description/idno, series_description/name, series_description/database_id",
        "top": max(5, int(top)),
        "filter": "type eq 'indicator' and series_description/database_id eq 'WB_WDI'",
    }
    try:
        js = data360_request_json(payload)
        values = js.get("value", []) if isinstance(js, dict) else []
    except Exception:
        # Fallback WB catalog
        return wb_indicator_catalog(keyword, max_pages=2)

    rows = []
    for item in values:
        sd = item.get("series_description") or {}
        full_id = sd.get("idno") or item.get("series_description/idno", "")
        dbid = sd.get("database_id") or item.get("series_description/database_id", "")
        if dbid != "WB_WDI" or not full_id:
            continue

        short_underscore = _cut_wb_id(full_id)   # SP_POP_TOTL
        display_code = _format_dot(short_underscore)  # SP.POP.TOTL
        name = sd.get("name") or item.get("series_description/name", "")
        if display_code and name:
            rows.append({
                "display_code": display_code,
                "name": name,
                "wb_id": "WB_WDI",
                "full_id": full_id,  # gi·ªØ l·∫°i ƒë·ªÉ mapping ng∆∞·ª£c n·∫øu c·∫ßn
            })

    df = pd.DataFrame(rows).drop_duplicates(subset=["display_code"]).sort_values("name").reset_index(drop=True)
    if df.empty:
        # Fallback WB catalog
        return wb_indicator_catalog(keyword, max_pages=2)
    return df

# ---------------- Fetch data (World Bank v2) ----------------
@st.cache_data(show_spinner=False, ttl=60*30)
def wb_fetch_series(country_code: str, wb_dot_id: str, year_from: int, year_to: int) -> pd.DataFrame:
    """
    Tr·∫£ v·ªÅ DF c·ªôt: Year, Country, IndicatorID, Value
    wb_dot_id v√≠ d·ª•: NY.GDP.MKTP.CD
    """
    js = http_get_json(
        f"{WB_BASE}/country/{country_code}/indicator/{wb_dot_id}",
        {"format": "json", "per_page": 20000, "date": f"{year_from}:{year_to}"}
    )

    # Defensive
    if not isinstance(js, list) or len(js) < 2:
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])
    if isinstance(js[0], dict) and js[0].get("message"):
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])
    _, data = js
    if not isinstance(data, list):
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])

    rows = []
    for d in data:
        year = d.get("date")
        if not str(year).isdigit():
            continue
        rows.append({
            "Year": int(year),
            "Country": (d.get("country") or {}).get("value", country_code),
            "IndicatorID": (d.get("indicator") or {}).get("id", wb_dot_id),
            "Value": d.get("value", None),
        })
    out = pd.DataFrame(rows).dropna(subset=["Year"])
    return out.sort_values("Year") if not out.empty else pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])

def pivot_wide_with_missing(df_long: pd.DataFrame, id_to_name: Dict[str,str], expected_names: List[str]) -> pd.DataFrame:
    """
    Pivot long -> wide (Year, Country, columns by IndicatorName).
    ƒê·∫£m b·∫£o m·ªçi 'expected_names' ƒë·ªÅu l√† c·ªôt trong wide, k·ªÉ c·∫£ n·∫øu thi·∫øu d·ªØ li·ªáu (ƒëi·ªÅn NaN).
    """
    if df_long is None or df_long.empty:
        # Tr·∫£ khung tr·ªëng v·ªõi ƒë·∫ßy ƒë·ªß c·ªôt
        cols = ["Year","Country"] + list(expected_names)
        return pd.DataFrame(columns=cols)

    df = df_long.copy()
    df["IndicatorName"] = df["IndicatorID"].map(id_to_name).fillna(df["IndicatorID"])
    wide = df.pivot_table(index=["Year","Country"], columns="IndicatorName", values="Value", aggfunc="first")
    wide = wide.reset_index().sort_values(["Country","Year"])

    # B·ªï sung c·ªôt c√≤n thi·∫øu
    for col in expected_names:
        if col not in wide.columns:
            wide[col] = np.nan

    # S·∫Øp x·∫øp c·ªôt: Year, Country, r·ªìi theo danh s√°ch ƒë·∫ßu v√†o
    ordered = ["Year","Country"] + [c for c in expected_names]
    return wide[ordered]

# ---------------- NA handling ----------------
def handle_na(df: pd.DataFrame, na_method: str) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    if na_method == "Gi·ªØ nguy√™n (N/A)":
        return df
    if na_method == "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)":
        return df.sort_values(["Country","Year"]).groupby("Country").ffill()
    if na_method == "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)":
        num = df.select_dtypes(include=[np.number])
        df[num.columns] = num.apply(lambda x: x.fillna(x.mean()), axis=0)
        return df
    return df

# ---------------- UI ----------------
st.set_page_config(page_title="Data360 ‚Üí World Bank (WB_WDI) ‚Äî Fixed", layout="wide", initial_sidebar_state="expanded")
st.title("üîé Data360 ‚Üí World Bank (WB_WDI) ‚Äî Fixed")
st.caption("Search indicator qua Data360 (l·ªçc WB_WDI, ID chu·∫©n). B·∫£ng d·ªØ li·ªáu ƒë·∫ßu ra d·∫°ng r·ªông: **Year | Country | ...**")

# Sidebar: Country + Year range
st.sidebar.header("Thi·∫øt l·∫≠p")
countries_df = wb_list_countries()
names = countries_df["name"].tolist()
default_idx = names.index("Viet Nam") if "Viet Nam" in names else 0
country_display = st.sidebar.selectbox(
    "Qu·ªëc gia",
    [f"{r.name} ({r.code})" for r in countries_df.itertuples()],
    index=default_idx
)
country_code = country_display.split("(")[-1].strip(")")
selected_country_name = country_display.split("(")[0].strip()

min_year, max_year = DEFAULT_DATE_RANGE
c1, c2 = st.sidebar.columns(2)
y_from = c1.number_input("T·ª´ nƒÉm", min_value=1960, max_value=2100, value=min_year, step=1)
y_to   = c2.number_input("ƒê·∫øn nƒÉm", min_value=1960, max_value=2100, value=max_year, step=1)

# Sidebar: Search indicators via Data360
st.sidebar.subheader("T√¨m & ch·ªçn ch·ªâ s·ªë (Data360 ‚Üí WB_WDI)")
kw = st.sidebar.text_input("T·ª´ kho√° (vd: GDP, CPI, inflation...)", value="GDP")

# NA method
st.sidebar.subheader("X·ª≠ l√Ω d·ªØ li·ªáu (N/A)")
na_method = st.sidebar.selectbox(
    "Ph∆∞∆°ng √°n x·ª≠ l√Ω N/A",
    ["Gi·ªØ nguy√™n (N/A)", "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)", "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)"],
    index=0
)

if "ind_df_cache_d360" not in st.session_state:
    st.session_state["ind_df_cache_d360"] = pd.DataFrame()

if st.sidebar.button("üîç T√¨m ch·ªâ s·ªë"):
    with st.spinner("ƒêang t√¨m indicators t·ª´ Data360 (l·ªçc WB_WDI)‚Ä¶"):
        st.session_state["ind_df_cache_d360"] = data360_search_indicators(kw, top=40)

ind_df = st.session_state["ind_df_cache_d360"]
with st.sidebar.expander("K·∫øt qu·∫£ t√¨m th·∫•y", expanded=False):
    if ind_df.empty:
        st.info("Nh·∫•n **T√¨m ch·ªâ s·ªë** ƒë·ªÉ tra c·ª©u.")
    else:
        st.dataframe(
            ind_df.rename(columns={
                "display_code": "Indicator",
                "name": "T√™n ch·ªâ s·ªë",
                "wb_id": "WB_ID",
                "full_id": "Full ID"
            })[["Indicator","T√™n ch·ªâ s·ªë","WB_ID","Full ID"]],
            use_container_width=True, height=260
        )

# Ch·ªçn theo t√™n (ƒë·ªÉ hi·ªÉn th·ªã c·ªôt ƒë√∫ng chu·∫©n)
indicator_names = ind_df["name"].tolist() if not ind_df.empty else []
selected_indicator_names = st.sidebar.multiselect(
    "Ch·ªçn **t√™n** ch·ªâ s·ªë ƒë·ªÉ l·∫•y d·ªØ li·ªáu",
    options=indicator_names,
    default=indicator_names[:2] if indicator_names else []
)

# Mapping: name -> dot id (SP.POP.TOTL), id_to_name (dot id -> *T√™n ch·ªâ s·ªë*)
name_to_dot = {row["name"]: row["display_code"] for _, row in (ind_df if not ind_df.empty else pd.DataFrame()).iterrows()}
dot_to_name = {v: k for k, v in name_to_dot.items()}

# ---------------- Tabs ----------------
tabs = st.tabs(["üìä D·ªØ li·ªáu","üìà Bi·ªÉu ƒë·ªì","üßÆ Th·ªëng k√™","üì• T·∫£i CSV","ü§ñ AI"])

# == TAB 1: D·ªÆ LI·ªÜU ==
with tabs[0]:
    st.subheader("D·ªØ li·ªáu (d·∫°ng r·ªông)")
    if st.button("üì• L·∫•y d·ªØ li·ªáu"):
        if not selected_indicator_names:
            st.warning("Ch·ªçn √≠t nh·∫•t m·ªôt *t√™n* ch·ªâ s·ªë.")
            st.stop()

        chosen_dot_ids = [name_to_dot[n] for n in selected_indicator_names if n in name_to_dot]

        all_long = []
        with st.spinner(f"T·∫£i {len(chosen_dot_ids)} ch·ªâ s·ªë cho {country_code}‚Ä¶"):
            for iid in chosen_dot_ids:
                df_fetch = wb_fetch_series(country_code, iid, int(y_from), int(y_to))
                if df_fetch is not None and not df_fetch.empty:
                    all_long.append(df_fetch)
                else:
                    # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu, v·∫´n t·∫°o khung r·ªóng ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ c·ªôt sau pivot
                    all_long.append(pd.DataFrame(columns=["Year","Country","IndicatorID","Value"]))

                time.sleep(0.25)  # nho nh·ªè tr√°nh ƒë·ª•ng rate limit

        # G·ªôp long
        if not all_long:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p cho ph·∫°m vi nƒÉm/ch·ªâ s·ªë ƒë√£ ch·ªçn.")
            st.stop()

        df_long = pd.concat(all_long, ignore_index=True) if len(all_long) > 1 else (all_long[0] if all_long else pd.DataFrame())
        # ƒê·∫£m b·∫£o IndicatorID l√† dot id (ƒë√∫ng chu·∫©n)
        if not df_long.empty:
            # M·ªôt s·ªë API tr·∫£ indicator.id s·∫µn dot id, nh∆∞ng c·ª© chu·∫©n ho√° t√™n map
            pass

        # Pivot d·∫°ng r·ªông + B·ªî SUNG c·ªôt thi·∫øu
        expected_names = [n for n in selected_indicator_names]  # c·ªôt c·∫ßn c√≥ theo t√™n (label)
        id_to_name = {dot: dot_to_name.get(dot, dot) for dot in chosen_dot_ids}  # map dot ‚Üí name
        df_wide = pivot_wide_with_missing(df_long, id_to_name, expected_names)

        # X·ª≠ l√Ω N/A theo tu·ª≥ ch·ªçn
        df_wide = handle_na(df_wide, na_method)

        st.session_state["wb_df_wide"] = df_wide
        st.success("‚úÖ ƒê√£ t·∫£i v√† chu·∫©n ho√° d·ªØ li·ªáu.")
        st.dataframe(df_wide.set_index("Year"), use_container_width=True)

def _get_df_wide():
    return st.session_state.get("wb_df_wide", pd.DataFrame())

# == TAB 2: BI·ªÇU ƒê·ªí ==
with tabs[1]:
    st.subheader("Bi·ªÉu ƒë·ªì")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i.")
    else:
        cols = [c for c in df.columns if c not in ("Year","Country")]
        choose = st.multiselect("Ch·ªçn c·ªôt v·∫Ω", options=cols, default=cols[:min(4, len(cols))])
        if choose:
            st.plotly_chart(px.line(df, x="Year", y=choose, color="Country", markers=True, title="Xu h∆∞·ªõng"), use_container_width=True)

            if len(choose) > 1:
                df_sel = df[choose].apply(pd.to_numeric, errors="coerce")
                df_sel = df_sel.dropna(axis=1, how="all")
                if df_sel.shape[1] >= 2:
                    corr = df_sel.corr().fillna(0)
                    hm = ff.create_annotated_heatmap(
                        z=corr.values,
                        x=corr.columns.tolist(),
                        y=corr.index.tolist(),
                        colorscale="Viridis",
                        annotation_text=corr.round(2).values,
                        showscale=True,
                    )
                    st.plotly_chart(hm, use_container_width=True)
                else:
                    st.info("C√°c c·ªôt ƒë∆∞·ª£c ch·ªçn kh√¥ng ƒë·ªß d·ªØ li·ªáu s·ªë ƒë·ªÉ t√≠nh t∆∞∆°ng quan.")

# == TAB 3: TH·ªêNG K√ä ==
with tabs[2]:
    st.subheader("Th·ªëng k√™ m√¥ t·∫£")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        cols = [c for c in df.columns if c not in ("Year","Country")]
        if not cols:
            st.info("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ th·ªëng k√™.")
        else:
            stats = df[cols].apply(pd.to_numeric, errors="coerce").describe().T
            stats["CV"] = (stats["std"]/stats["mean"]).abs()
            st.dataframe(
                stats[["mean","std","min","50%","max","CV"]]
                .rename(columns={"mean":"Mean","std":"Std","50%":"Median"}),
                use_container_width=True
            )

# == TAB 4: CSV ==
with tabs[3]:
    st.subheader("T·∫£i CSV")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        st.download_button(
            "üì• T·∫£i CSV",
            data=df.to_csv(index=False, encoding="utf-8-sig"),
            file_name=f"wb_{country_code}_{y_from}_{y_to}.csv",
            mime="text/csv"
        )

# == TAB 5: AI ==
with tabs[4]:
    st.subheader("AI insight (tu·ª≥ ch·ªçn)")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        if genai is None or not os.environ.get("GOOGLE_API_KEY", ""):
            st.info("Ch∆∞a c·∫•u h√¨nh GOOGLE_API_KEY n√™n b·ªè qua AI insight.")
        else:
            try:
                genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
                model = genai.GenerativeModel("gemini-2.5-flash")
                data_string = df.to_csv(index=False)
                prompt = (
                    "B·∫°n l√† chuy√™n gia d·ªØ li·ªáu kinh t·∫ø. H√£y t√≥m t·∫Øt xu h∆∞·ªõng ch√≠nh, ƒëi·ªÉm b·∫•t th∆∞·ªùng, "
                    f"v√† g·ª£i √Ω 2‚Äì3 insight h√†nh ƒë·ªông cho qu·ªëc gia {selected_country_name} "
                    f"trong giai ƒëo·∫°n {y_from}-{y_to}. D·ªØ li·ªáu CSV:\n\n{data_string}\n\n"
                    "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·∫°ng bullet."
                )
                with st.spinner("AI ƒëang ph√¢n t√≠ch‚Ä¶"):
                    resp = model.generate_content(prompt)
                st.markdown(resp.text or "_Kh√¥ng c√≥ ph·∫£n h·ªìi_")
            except Exception as e:
                st.warning(f"AI l·ªói: {e}")
