# =========================
# app.py ‚Äî Streamlit + Data360 search (WB_WDI) + Data360 data + Full Tabs
# =========================

import ssl, certifi
ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())

import re
import time
from typing import Dict, Any, Optional, List

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.figure_factory as ff

# (Tu·ª≥ ch·ªçn) AI qua Google Gemini
try:
    import google.generativeai as genai
except Exception:
    genai = None

# ---------- Page ----------
st.set_page_config(page_title="World Bank ‚Äî Data360 (WB_WDI)", layout="wide", initial_sidebar_state="expanded")
st.title("T·∫£i d·ªØ li·ªáu tr·ª±c ti·∫øp t·ª´ World Bank (qua Data360)")
st.caption("Ch·ªçn **t√™n** ch·ªâ s·ªë ‚Üí h·ªá th·ªëng t·ª± t√¨m **ID** (WDI) ‚Üí g·ªçi Data360 **/data** ‚Üí hi·ªÉn th·ªã b·∫£ng/pivot/bi·ªÉu ƒë·ªì/CSV/AI.")

# ---------- Config ----------
WB_BASE = "https://api.worldbank.org/v2"            # ch·ªâ d√πng cho fallback catalog
DATA360_BASE = "https://dataapi.worldbank.org/data360"  # ƒë·ªïi n·∫øu m√¥i tr∆∞·ªùng kh√°c

DEFAULT_DATE_RANGE = (2004, 2024)

UA = "Streamlit-WB-Client/1.0 (contact: you@example.com)"
HEADERS = {"User-Agent": UA}
DATA360_HEADERS = {"User-Agent": UA, "Accept": "application/json", "Content-Type": "application/json"}

# ---------- Small utils ----------
def _to_int(x, default=0):
    try:
        return int(x)
    except (TypeError, ValueError):
        return default

def _to_float(x, default=None):
    try:
        if x is None or (isinstance(x, str) and x.strip() == ""):
            return default
        return float(x)
    except (TypeError, ValueError):
        return default

def handle_na(df, na_method="Gi·ªØ nguy√™n (N/A)"):
    if df is None or df.empty:
        return df
    if na_method == "Gi·ªØ nguy√™n (N/A)":
        return df
    elif na_method == "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)":
        return df.ffill()
    elif na_method == "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)":
        return df.apply(lambda x: x.fillna(x.mean()), axis=0)
    else:
        return df

# ---------- HTTP helpers ----------
def http_get_json(url: str, params: Dict[str, Any], headers=None, retries: int = 4, backoff: float = 1.5):
    attempt, last_err = 0, None
    headers = headers or HEADERS
    while attempt <= retries:
        try:
            r = requests.get(url, params=params, headers=headers, timeout=60)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except requests.HTTPError as e:
            last_err = e
            resp = getattr(e, "response", None)
            if resp is not None and resp.status_code == 429:
                ra = resp.headers.get("Retry-After")
                sleep_s = max(backoff, int(ra)) if ra and str(ra).isdigit() else backoff * (2 ** attempt)
            else:
                sleep_s = backoff * (2 ** attempt)
            time.sleep(min(sleep_s, 12))
            attempt += 1
        except requests.RequestException as e:
            last_err = e
            time.sleep(backoff * (2 ** attempt))
            attempt += 1
    raise last_err

def data360_request_json(method: str, endpoint: str, *, params: Dict[str, Any] | None = None,
                         json_payload: Dict[str, Any] | None = None, retries: int = 4, backoff: float = 1.5):
    attempt, last_err = 0, None
    url = f"{DATA360_BASE}{endpoint}"
    while attempt <= retries:
        try:
            resp = requests.request(method, url, params=params, json=json_payload,
                                    headers=DATA360_HEADERS, timeout=60)
            if resp.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{resp.status_code} {resp.reason}", response=resp)
            resp.raise_for_status()
            return resp.json()
        except requests.HTTPError as e:
            last_err = e
            resp = getattr(e, "response", None)
            if resp is not None and resp.status_code == 429:
                ra = resp.headers.get("Retry-After")
                sleep_s = max(backoff, int(ra)) if ra and str(ra).isdigit() else backoff * (2 ** attempt)
            else:
                sleep_s = backoff * (2 ** attempt)
            time.sleep(min(sleep_s, 12))
            attempt += 1
        except requests.RequestException as e:
            last_err = e
            time.sleep(backoff * (2 ** attempt))
            attempt += 1
    raise last_err

# ---------- WDI ID helpers ----------
def _format_indicator_code(raw: str) -> str:
    cleaned = (raw or "").strip("_")
    return cleaned.replace("_", ".")

def _extract_indicator_parts(full_id: str) -> tuple[str, str]:
    parts = (full_id or "").split("_", 2)
    if len(parts) >= 3:
        return "_".join(parts[:2]), parts[2]
    return "", full_id or ""

# ---------- Catalog ----------
@st.cache_data(show_spinner=False, ttl=24*3600)
def wb_list_countries() -> pd.DataFrame:
    out, page = [], 1
    while True:
        js = http_get_json(f"{WB_BASE}/country", {"format": "json", "per_page": 400, "page": page})
        if not isinstance(js, list) or len(js) < 2:
            break
        meta, data = js
        per_page, total = _to_int(meta.get("per_page", 0)), _to_int(meta.get("total", 0))
        for c in data:
            if (c.get("region") or {}).get("id") != "NA":
                out.append({"code": c["id"], "name": c["name"]})
        if page * per_page >= total:
            break
        page += 1
    return pd.DataFrame(out).sort_values("name").reset_index(drop=True)

@st.cache_data(show_spinner=False, ttl=6*3600)
def wb_indicator_catalog() -> pd.DataFrame:
    base = f"{WB_BASE}/indicator"
    per_page = 20000
    js = http_get_json(f"{base}?format=json&per_page={per_page}", {})
    items = js[1] if isinstance(js, list) and len(js) > 1 else []
    rows = []
    for it in items:
        iid = it.get("id")  # NY.GDP.MKTP.CD
        name = it.get("name") or iid
        if iid and re.match(r"^[A-Z]{2}\.[A-Z0-9]+\.[A-Z0-9.]+$", iid):
            rows.append({"name": name, "wb_dot_id": iid})
    return pd.DataFrame(rows)

# ---------- SEARCH ----------
@st.cache_data(show_spinner=False, ttl=6*3600)
def wb_search_indicators(keyword: str, top: int = 40) -> pd.DataFrame:
    """
    Search indicators qua Data360 (/searchv2) -> ch·ªâ nh·∫≠n idno b·∫Øt ƒë·∫ßu WB_WDI_.
    N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£ h·ª£p l·ªá -> fallback World Bank catalog.
    Tr·∫£ DF: id (full_id), name, display_code (pretty), wb_id
    """
    keyword = (keyword or "").strip()
    try:
        payload = {
            "count": True,
            "search": keyword,
            "select": "series_description/idno, series_description/name, series_description/database_id",
            "top": max(5, top),
            "filter": "series_description/database_id eq 'WB_WDI' and type eq 'indicator'"
        }
        js = data360_request_json("POST", "/searchv2", json_payload=payload)
        values = js.get("value", []) if isinstance(js, dict) else []
        rows = []
        for item in values:
            sd = item.get("series_description") or {}
            full_id = sd.get("idno") or item.get("series_description/idno", "")
            dbid = sd.get("database_id") or item.get("series_description/database_id", "")
            if dbid != "WB_WDI" or not full_id or not full_id.startswith("WB_WDI_"):
                continue
            short_id = _extract_indicator_parts(full_id)[1]        # SP_POP_TOTL
            display_code = _format_indicator_code(short_id)        # SP.POP.TOTL
            rows.append({
                "id": full_id,                 # WB_WDI_SP_POP_TOTL
                "name": sd.get("name") or item.get("series_description/name", ""),
                "display_code": display_code,  # pretty: SP.POP.TOTL
                "wb_id": dbid
            })
        if rows:
            return (pd.DataFrame(rows)
                    .drop_duplicates(subset=["id"])
                    .sort_values("name")
                    .reset_index(drop=True))
    except Exception:
        pass

    # Fallback: WB catalog
    cat = wb_indicator_catalog()
    if keyword:
        k = keyword.lower()
        cat = cat[cat["name"].str.lower().str.contains(k) | cat["wb_dot_id"].str.lower().str.contains(k)]
    cat = cat.head(top)
    # ƒê·ªìng nh·∫•t schema v·ªõi k·∫øt qu·∫£ Data360
    cat = cat.assign(id=None, display_code=cat["wb_dot_id"], wb_id="WB_WDI")
    return cat.rename(columns={"wb_dot_id": "display_code"})[["id", "name", "display_code", "wb_id"]]

# ---------- FETCH DATA (Data360 /data) ----------
@st.cache_data(show_spinner=False, ttl=6*3600)
def wb_fetch_series(country_code: str, indicator_full_id: str, year_from: int, year_to: int) -> pd.DataFrame:
    """
    GET /data?DATABASE_ID=WB_WDI&INDICATOR=<full>&REF_AREA=<country>&TIME_PERIOD=YYYY:YYYY
    Chu·∫©n ho√° output -> Year, Country, IndicatorID, Value
    """
    params = {
        "DATABASE_ID": "WB_WDI",
        "INDICATOR": indicator_full_id,
        "REF_AREA": country_code,
        "TIME_PERIOD": f"{year_from}:{year_to}",
    }
    js = data360_request_json("GET", "/data", params=params)

    values = []
    if isinstance(js, dict):
        if "value" in js and isinstance(js["value"], list):
            values = js["value"]
        elif "data" in js and isinstance(js["data"], list):
            values = js["data"]

    rows = []
    for entry in values:
        ref_area = entry.get("REF_AREA") or entry.get("REFAREA")
        period = str(entry.get("TIME_PERIOD", "") or entry.get("TIMEPERIOD", "")).strip()
        if ref_area != country_code or not period:
            continue
        year_str = period[:4] if len(period) >= 4 else period
        if not year_str.isdigit():
            continue
        val = entry.get("OBS_VALUE")
        if val is None:
            val = entry.get("VALUE")
        rows.append(
            {
                "Year": int(year_str),
                "Country": country_code,
                "IndicatorID": indicator_full_id,
                "Value": _to_float(val),
            }
        )
    if not rows:
        return pd.DataFrame(columns=["Year", "Country", "IndicatorID", "Value"])
    return pd.DataFrame(rows).dropna(subset=["Year"]).sort_values("Year")

def pivot_wide(df_long: pd.DataFrame, id_to_name: dict) -> pd.DataFrame:
    """Long (Year, Country, IndicatorID, Value) -> Wide (m·ªói indicator 1 c·ªôt)."""
    if df_long is None or df_long.empty:
        return pd.DataFrame()
    df = df_long.copy()
    df["IndicatorName"] = df["IndicatorID"].map(id_to_name).fillna(df["IndicatorID"])
    wide = df.pivot_table(
        index=["Year", "Country"],
        columns="IndicatorName",
        values="Value",
        aggfunc="first"
    )
    return wide.reset_index().sort_values(["Country", "Year"])

# ---------------- Sidebar ----------------
st.sidebar.header("Thi·∫øt l·∫≠p")

# Qu·ªëc gia: ALL ho·∫∑c nh·∫≠p/ho·∫∑c ch·ªçn danh s√°ch
st.sidebar.subheader("Qu·ªëc gia (REF_AREA)")
all_countries = st.sidebar.checkbox("ALL qu·ªëc gia", value=False)
countries_df = wb_list_countries()
names = countries_df["name"].tolist()
default_idx = names.index("Viet Nam") if "Viet Nam" in names else 0
country_select = st.sidebar.selectbox(
    "Ch·ªçn nhanh 1 qu·ªëc gia",
    [f"{r.name} ({r.code})" for r in countries_df.itertuples()],
    index=default_idx
)
manual_codes = st.sidebar.text_input("Ho·∫∑c nh·∫≠p m√£ (1-n, c√°ch nhau d·∫•u ph·∫©y)", value="")

def resolve_country_list() -> List[str]:
    if all_countries:
        return ["ALL"]
    manual = [x.strip() for x in manual_codes.split(",") if x.strip()]
    if manual:
        return manual
    # l·∫•y t·ª´ selectbox
    return [country_select.split("(")[-1].strip(")")]

country_list = resolve_country_list()

min_year, max_year = DEFAULT_DATE_RANGE
c1, c2 = st.sidebar.columns(2)
y_from = c1.number_input("T·ª´ nƒÉm", min_value=1960, max_value=2100, value=min_year, step=1)
y_to   = c2.number_input("ƒê·∫øn nƒÉm", min_value=1960, max_value=2100, value=max_year, step=1)

st.sidebar.subheader("T√¨m & ch·ªçn ch·ªâ s·ªë (theo *t√™n*)")
kw = st.sidebar.text_input("T·ª´ kho√° (vd: GDP, CPI, inflation...)", value="GDP")

# X·ª≠ l√Ω N/A
st.sidebar.subheader("X·ª≠ l√Ω d·ªØ li·ªáu (N/A)")
na_method = st.sidebar.selectbox(
    "Ph∆∞∆°ng √°n x·ª≠ l√Ω",
    ["Gi·ªØ nguy√™n (N/A)", "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)", "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)"]
)

if "ind_df_cache_api" not in st.session_state:
    st.session_state["ind_df_cache_api"] = pd.DataFrame()

if st.sidebar.button("üîç T√¨m ch·ªâ s·ªë"):
    with st.spinner("ƒêang t√¨m indicators..."):
        st.session_state["ind_df_cache_api"] = wb_search_indicators(kw, top=60)

ind_df = st.session_state["ind_df_cache_api"]

with st.sidebar.expander("K·∫øt qu·∫£ t√¨m th·∫•y", expanded=False):
    if ind_df.empty:
        st.info("Nh·∫•n **T√¨m ch·ªâ s·ªë** ƒë·ªÉ tra c·ª©u.")
    else:
        # Hi·ªÉn th·ªã an to√†n: ch·ªâ d√πng c·ªôt t·ªìn t·∫°i + lo·∫°i tr√πng t√™n
        cols_map = {"display_code": "Indicator (WDI)", "name": "T√™n ch·ªâ s·ªë", "wb_id": "DB", "id": "Full ID"}
        available = [c for c in cols_map if c in ind_df.columns]
        display_cols = ind_df[available].rename(columns={c: cols_map[c] for c in available})
        display_cols = display_cols.loc[:, ~display_cols.columns.duplicated()].copy()
        st.dataframe(display_cols, use_container_width=True, height=260)

# ---- Ch·ªçn indicator (c√≥ ALL) ----
indicator_names = ind_df["name"].tolist() if not ind_df.empty else []
options = (["ALL (ch·ªçn t·∫•t c·∫£)"] + indicator_names) if indicator_names else []
default_selected = ["ALL (ch·ªçn t·∫•t c·∫£)"] if options else []
selected_indicator_names = st.sidebar.multiselect(
    "Ch·ªçn **t√™n** ch·ªâ s·ªë ƒë·ªÉ l·∫•y d·ªØ li·ªáu",
    options=options,
    default=default_selected
)
if "ALL (ch·ªçn t·∫•t c·∫£)" in selected_indicator_names:
    selected_indicator_names = indicator_names

# Map name -> id / pretty ƒë·ªÉ g·ªçi /data (n·∫øu thi·∫øu id th√¨ suy ra t·ª´ pretty)
name_to_id = {row["name"]: row["id"] for _, row in (ind_df if not ind_df.empty else pd.DataFrame()).iterrows()}
name_to_pretty = {row["name"]: row["display_code"] for _, row in (ind_df if not ind_df.empty else pd.DataFrame()).iterrows()}

# Tabs
tabs = st.tabs(["üìä D·ªØ li·ªáu", "üìà Bi·ªÉu ƒë·ªì", "üßÆ Th·ªëng k√™", "üì• T·∫£i CSV", "ü§ñ AI"])

# == TAB 1: D·ªÆ LI·ªÜU ==
with tabs[0]:
    if st.button("üì• L·∫•y d·ªØ li·ªáu"):
        if not selected_indicator_names:
            st.warning("Ch·ªçn √≠t nh·∫•t m·ªôt *t√™n* ch·ªâ s·ªë.")
            st.stop()

        # Chu·∫©n ho√° danh s√°ch indicator full_id
        chosen_full_ids: List[str] = []
        id_to_name: Dict[str, str] = {}
        for n in selected_indicator_names:
            fid = name_to_id.get(n)
            if not fid:
                # fallback: suy ra t·ª´ pretty_id (vd NY.GDP.MKTP.CD -> WB_WDI_NY_GDP_MKTP_CD)
                pretty = name_to_pretty.get(n)
                if pretty:
                    fid = "WB_WDI_" + pretty.replace(".", "_")
            if fid:
                chosen_full_ids.append(fid)
                id_to_name[fid] = n

        if not chosen_full_ids:
            st.error("Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ID ch·ªâ ti√™u ƒë·ªÉ g·ªçi /data. H√£y th·ª≠ t√¨m l·∫°i b·∫±ng Data360.")
            st.stop()

        all_long = []
        with st.spinner(f"T·∫£i {len(chosen_full_ids)} ch·ªâ ti√™u cho {len(country_list)} qu·ªëc gia..."):
            for country_code in country_list:
                for ind_id in chosen_full_ids:
                    df_fetch = wb_fetch_series(country_code, ind_id, int(y_from), int(y_to))
                    if df_fetch is not None and not df_fetch.empty:
                        all_long.append(df_fetch)
                    time.sleep(0.05)

        if not all_long:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p cho ph·∫°m vi nƒÉm/ch·ªâ s·ªë ƒë√£ ch·ªçn.")
            st.stop()

        df_long = pd.concat(all_long, ignore_index=True)
        if df_long.empty:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi t·ªïng h·ª£p.")
            st.stop()

        df_wide = pivot_wide(df_long, id_to_name)
        df_wide = handle_na(df_wide, na_method)
        st.session_state["wb_df"] = df_wide

        st.success("‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu.")
        st.dataframe(df_wide.set_index(["Country", "Year"]), use_container_width=True)

def _get_df():
    return st.session_state.get("wb_df", pd.DataFrame())

# == TAB 2: BI·ªÇU ƒê·ªí ==
with tabs[1]:
    st.subheader("Bi·ªÉu ƒë·ªì")
    df = _get_df()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i.")
    else:
        df = handle_na(df, na_method)
        cols = [c for c in df.columns if c not in ("Year", "Country")]
        choose = st.multiselect("Ch·ªçn c·ªôt v·∫Ω", options=cols, default=cols[:min(6, len(cols))])
        group = st.selectbox("Nh√≥m theo", ["Country", "Kh√¥ng (g·ªôp)"], index=0)
        if choose:
            if group == "Country":
                fig = px.line(df, x="Year", y=choose, color="Country", markers=True)
            else:
                fig = px.line(df, x="Year", y=choose, markers=True)
            st.plotly_chart(fig, use_container_width=True)

            # Heatmap t∆∞∆°ng quan (n·∫øu ch·ªçn >1 c·ªôt, ch·ªâ t√≠nh tr√™n c√°c c·ªôt s·ªë)
            if len(choose) > 1:
                df_sel = df[choose].apply(pd.to_numeric, errors="coerce").dropna(axis=1, how="all")
                if df_sel.shape[1] >= 2:
                    corr = df_sel.corr().fillna(0)
                    hm = ff.create_annotated_heatmap(
                        z=corr.values,
                        x=corr.columns.tolist(),
                        y=corr.index.tolist(),
                        colorscale="Viridis",
                        annotation_text=corr.round(2).values,
                        showscale=True,
                    )
                    st.plotly_chart(hm, use_container_width=True)

# == TAB 3: TH·ªêNG K√ä ==
with tabs[2]:
    st.subheader("Th·ªëng k√™ m√¥ t·∫£")
    df = _get_df()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        df = handle_na(df, na_method)
        cols = [c for c in df.columns if c not in ("Year", "Country")]
        if not cols:
            st.info("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ th·ªëng k√™.")
        else:
            stats = df[cols].apply(pd.to_numeric, errors="coerce").describe().T
            stats["CV"] = (stats["std"] / stats["mean"]).abs()
            st.dataframe(
                stats[["mean", "std", "min", "50%", "max", "CV"]]
                .rename(columns={"mean": "Mean", "std": "Std", "50%": "Median"}),
                use_container_width=True
            )

# == TAB 4: T·∫¢I CSV ==
with tabs[3]:
    st.subheader("T·∫£i CSV")
    df = _get_df()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        st.download_button(
            "üì• T·∫£i CSV",
            data=df.to_csv(index=False, encoding="utf-8-sig"),
            file_name=f"wb_{int(y_from)}_{int(y_to)}_{'ALL' if 'ALL' in country_list else '-'.join(country_list)}.csv",
            mime="text/csv"
        )

# == TAB 5: AI PH√ÇN T√çCH ==
with tabs[4]:
    st.header("AI ph√¢n t√≠ch (tu·ª≥ ch·ªçn)")
    df = _get_df()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        if genai is None or not st.secrets.get("GEMINI_API_KEY"):
            st.info("Ch∆∞a c·∫•u h√¨nh GEMINI_API_KEY trong .streamlit/secrets.toml")
        else:
            try:
                genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
                model = genai.GenerativeModel('gemini-1.5-flash')
                sample = df.head(200).to_dict(orient="records")
                prompt = (
                    "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch kinh t·∫ø. H√£y t√≥m t·∫Øt xu h∆∞·ªõng ch√≠nh, ƒëi·ªÉm b·∫•t th∆∞·ªùng, "
                    "v√† ƒë∆∞a ra 3 khuy·∫øn ngh·ªã cho nh√† ho·∫°ch ƒë·ªãnh ch√≠nh s√°ch d·ª±a tr√™n d·ªØ li·ªáu sau:\n"
                    f"{sample}"
                )
                with st.spinner("AI ƒëang ph√¢n t√≠ch..."):
                    resp = model.generate_content(prompt)
                st.markdown(resp.text or "_Kh√¥ng c√≥ ph·∫£n h·ªìi_")
            except Exception as e:
                st.warning(f"AI l·ªói: {e}")
