# =========================
# python7_final.py ‚Äî Data360 (WB_WDI) search ‚Üí World Bank fetch
# - B·∫£ng search: ID (d·∫°ng ch·∫•m) | T√™n ch·ªâ s·ªë
# - Xu·∫•t d·ªØ li·ªáu d·∫°ng r·ªông: Year | Country | <T√™n ch·ªâ ti√™u 1> | <T√™n ch·ªâ ti√™u 2> | ...
# - B·∫£o ƒë·∫£m: ch·ªçn bao nhi√™u indicator ‚Üí c√≥ b·∫•y nhi√™u c·ªôt (k·ªÉ c·∫£ r·ªóng n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu)
# - T√≠nh nƒÉng: Bi·ªÉu ƒë·ªì, Heatmap, Th·ªëng k√™, CSV, AI (Gemini - tu·ª≥ ch·ªçn)
# =========================

import ssl, certifi
ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())

import os
import time
from typing import Dict, Any, Optional, List
import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.figure_factory as ff

# (tu·ª≥ ch·ªçn) AI insight
try:
    import google.generativeai as genai
except Exception:
    genai = None

# ---------------- Config ----------------
WB_BASE = "https://api.worldbank.org/v2"
DATA360_BASE_URL = os.environ.get("DATA360_BASE_URL", "https://api.data360.org")
D360_SEARCH_ENDPOINT = "/data360/searchv2"

HEADERS = {
    "User-Agent": "Streamlit-WB-Client/1.0",
    "Accept": "application/json",
    "Content-Type": "application/json",
}
REQ_TIMEOUT = 60
RETRIES = 4
BACKOFF = 1.6

DEFAULT_DATE_RANGE = (2004, 2024)

# ---------------- Retry helpers ----------------
def _sleep(attempt: int) -> float:
    return min(BACKOFF ** attempt, 12.0)

def http_get_json(url: str, params: Dict[str, Any]) -> Any:
    last_err = None
    for i in range(RETRIES + 1):
        try:
            r = requests.get(url, params=params, headers={"User-Agent": HEADERS["User-Agent"]}, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_sleep(i))
    raise RuntimeError(f"GET {url} failed after retries: {last_err}")

def data360_request_json(payload: Dict[str, Any]) -> Any:
    url = f"{DATA360_BASE_URL}{D360_SEARCH_ENDPOINT}"
    last_err = None
    for i in range(RETRIES + 1):
        try:
            r = requests.post(url, json=payload, headers=HEADERS, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_sleep(i))
    raise RuntimeError(f"POST {url} failed after retries: {last_err}")

# ---------------- Utilities ----------------
def _to_int(x, default=0):
    try:
        return int(x)
    except (TypeError, ValueError):
        return default

def _format_dot(code_underscore: str) -> str:
    """
    SP_POP_TOTL -> SP.POP.TOTL
    """
    return (code_underscore or "").strip("_").replace("_", ".")

def _cut_wb_id(full_id: str) -> str:
    """
    WB_WDI_SP_POP_TOTL -> SP_POP_TOTL
    (N·∫øu kh√¥ng ƒë√∫ng format th√¨ tr·∫£ nguy√™n)
    """
    s = full_id or ""
    return s[len("WB_WDI_"):] if s.startswith("WB_WDI_") else s

# ---------------- Country list ----------------
@st.cache_data(show_spinner=False, ttl=24*3600)
def wb_list_countries() -> pd.DataFrame:
    out, page = [], 1
    while True:
        js = http_get_json(f"{WB_BASE}/country", {"format":"json","per_page":400,"page":page})
        if not isinstance(js, list) or len(js) < 2:
            break
        meta, data = js
        per_page, total = _to_int(meta.get("per_page",0)), _to_int(meta.get("total",0))
        for c in data:
            # B·ªè nh√≥m Aggregates ("NA")
            if (c.get("region") or {}).get("id") != "NA":
                out.append({"code": c["id"], "name": c["name"]})
        if page * per_page >= total:
            break
        page += 1
    return pd.DataFrame(out).sort_values("name").reset_index(drop=True)

# ---------------- Indicator search (Data360 first, WB fallback) ----------------
@st.cache_data(show_spinner=False, ttl=6*3600)
def wb_indicator_catalog(keyword: str, max_pages: int = 2) -> pd.DataFrame:
    """
    Fallback: World Bank /indicator ‚Äî tr·∫£ "ID | T√™n ch·ªâ s·ªë"
    """
    results, page = [], 1
    key = (keyword or "").strip().lower()
    while page <= max_pages:
        js = http_get_json(f"{WB_BASE}/indicator", {"format":"json","per_page":5000,"page":page})
        if not isinstance(js, list) or len(js) < 2:
            break
        meta, data = js
        per_page, total = _to_int(meta.get("per_page",0)), _to_int(meta.get("total",0))
        for it in data:
            _id, _name = it.get("id",""), it.get("name","")
            if key and (key not in _name.lower() and key not in _id.lower()):
                continue
            results.append({"ID": _id, "T√™n ch·ªâ s·ªë": _name})
        if page * per_page >= total:
            break
        page += 1
    df = pd.DataFrame(results).drop_duplicates(subset=["ID"]).sort_values("T√™n ch·ªâ s·ªë").reset_index(drop=True)
    return df[["ID","T√™n ch·ªâ s·ªë"]]

@st.cache_data(show_spinner=False, ttl=6*3600)
def data360_search_indicators(keyword: str, top: int = 40) -> pd.DataFrame:
    """
    Search indicators via Data360 searchv2, filter only WB_WDI.
    Chu·∫©n ho√° hi·ªÉn th·ªã: b·∫£ng 2 c·ªôt "ID | T√™n ch·ªâ s·ªë".
    - ID ·ªü ƒë√¢y l√† d·∫°ng ch·∫•m: SP.POP.TOTL / NY.GDP.MKTP.CD.
    - Lo·∫°i b·ªè d·∫°ng '6.0.GDP_usd' b·∫±ng c√°ch ch·ªâ l·∫•y WB_WDI v√†
      convert 'WB_WDI_SP_POP_TOTL' -> 'SP.POP.TOTL'.
    """
    payload = {
        "count": False,
        "search": (keyword or "").strip(),
        "select": "series_description/idno, series_description/name, series_description/database_id",
        "top": max(5, int(top)),
        "filter": "type eq 'indicator' and series_description/database_id eq 'WB_WDI'",
    }
    try:
        js = data360_request_json(payload)
        values = js.get("value", []) if isinstance(js, dict) else []
    except Exception:
        # Fallback WB catalog
        return wb_indicator_catalog(keyword, max_pages=2)

    rows = []
    for item in values:
        sd = item.get("series_description") or {}
        full_id = sd.get("idno") or item.get("series_description/idno", "")
        dbid = sd.get("database_id") or item.get("series_description/database_id", "")
        if dbid != "WB_WDI" or not full_id:
            continue
        short_underscore = _cut_wb_id(full_id)             # SP_POP_TOTL
        display_code = _format_dot(short_underscore)       # SP.POP.TOTL
        name = sd.get("name") or item.get("series_description/name", "")
        if display_code and name:
            rows.append({"ID": display_code, "T√™n ch·ªâ s·ªë": name})

    df = pd.DataFrame(rows).drop_duplicates(subset=["ID"]).sort_values("T√™n ch·ªâ s·ªë").reset_index(drop=True)
    if df.empty:
        return wb_indicator_catalog(keyword, max_pages=2)
    return df[["ID","T√™n ch·ªâ s·ªë"]]

# ---------------- Fetch data (World Bank v2) ----------------
@st.cache_data(show_spinner=False, ttl=60*30)
def wb_fetch_series(country_code: str, wb_dot_id: str, year_from: int, year_to: int) -> pd.DataFrame:
    """
    Tr·∫£ v·ªÅ DF c·ªôt: Year, Country, IndicatorID, Value
    wb_dot_id v√≠ d·ª•: NY.GDP.MKTP.CD
    """
    js = http_get_json(
        f"{WB_BASE}/country/{country_code}/indicator/{wb_dot_id}",
        {"format": "json", "per_page": 20000, "date": f"{year_from}:{year_to}"}
    )

    # Defensive
    if not isinstance(js, list) or len(js) < 2:
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])
    if isinstance(js[0], dict) and js[0].get("message"):
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])
    _, data = js
    if not isinstance(data, list):
        return pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])

    rows = []
    for d in data:
        year = d.get("date")
        if not str(year).isdigit():
            continue
        rows.append({
            "Year": int(year),
            "Country": (d.get("country") or {}).get("value", country_code),
            "IndicatorID": (d.get("indicator") or {}).get("id", wb_dot_id),
            "Value": d.get("value", None),
        })
    out = pd.DataFrame(rows).dropna(subset=["Year"])
    return out.sort_values("Year") if not out.empty else pd.DataFrame(columns=["Year","Country","IndicatorID","Value"])

def pivot_wide_with_missing(df_long: pd.DataFrame, id_to_name: Dict[str,str], expected_names: List[str]) -> pd.DataFrame:
    """
    Pivot long -> wide (Year, Country, columns by IndicatorName).
    ƒê·∫£m b·∫£o m·ªçi 'expected_names' ƒë·ªÅu l√† c·ªôt trong wide, k·ªÉ c·∫£ n·∫øu thi·∫øu d·ªØ li·ªáu (ƒëi·ªÅn NaN).
    """
    if df_long is None or df_long.empty:
        # Tr·∫£ khung tr·ªëng v·ªõi ƒë·∫ßy ƒë·ªß c·ªôt
        cols = ["Year","Country"] + list(expected_names)
        return pd.DataFrame(columns=cols)

    df = df_long.copy()
    df["IndicatorName"] = df["IndicatorID"].map(id_to_name).fillna(df["IndicatorID"])
    wide = df.pivot_table(index=["Year","Country"], columns="IndicatorName", values="Value", aggfunc="first")
    wide = wide.reset_index().sort_values(["Country","Year"])

    # B·ªï sung c·ªôt c√≤n thi·∫øu
    for col in expected_names:
        if col not in wide.columns:
            wide[col] = np.nan

    # S·∫Øp x·∫øp c·ªôt: Year, Country, r·ªìi theo danh s√°ch ƒë·∫ßu v√†o
    ordered = ["Year","Country"] + [c for c in expected_names]
    return wide[ordered]

# ---------------- NA handling ----------------
def handle_na(df: pd.DataFrame, na_method: str) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    if na_method == "Gi·ªØ nguy√™n (N/A)":
        return df
    if na_method == "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)":
        return df.sort_values(["Country","Year"]).groupby("Country").ffill()
    if na_method == "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)":
        num = df.select_dtypes(include=[np.number])
        df[num.columns] = num.apply(lambda x: x.fillna(x.mean()), axis=0)
        return df
    return df

# ---------------- UI ----------------
st.set_page_config(page_title="Data360 ‚Üí World Bank (WB_WDI) ‚Äî Final", layout="wide", initial_sidebar_state="expanded")
st.title("üîé Data360 ‚Üí World Bank (WB_WDI) ‚Äî Final")
st.caption("Search indicator qua Data360 (l·ªçc WB_WDI). B·∫£ng k·∫øt qu·∫£ t√¨m: **ID | T√™n ch·ªâ s·ªë**. D·ªØ li·ªáu xu·∫•t: **Year | Country | ‚Ä¶**")

# Sidebar: Country + Year range
st.sidebar.header("Thi·∫øt l·∫≠p")
countries_df = wb_list_countries()
names = countries_df["name"].tolist()
default_idx = names.index("Viet Nam") if "Viet Nam" in names else 0
country_display = st.sidebar.selectbox(
    "Qu·ªëc gia",
    [f"{r.name} ({r.code})" for r in countries_df.itertuples()],
    index=default_idx
)
country_code = country_display.split("(")[-1].strip(")")
selected_country_name = country_display.split("(")[0].strip()

min_year, max_year = DEFAULT_DATE_RANGE
c1, c2 = st.sidebar.columns(2)
y_from = c1.number_input("T·ª´ nƒÉm", min_value=1960, max_value=2100, value=min_year, step=1)
y_to   = c2.number_input("ƒê·∫øn nƒÉm", min_value=1960, max_value=2100, value=max_year, step=1)

# Sidebar: Search indicators via Data360
st.sidebar.subheader("T√¨m & ch·ªçn ch·ªâ s·ªë (Data360 ‚Üí WB_WDI)")
kw = st.sidebar.text_input("T·ª´ kho√° (vd: GDP, CPI, inflation...)", value="GDP")

# NA method
st.sidebar.subheader("X·ª≠ l√Ω d·ªØ li·ªáu (N/A)")
na_method = st.sidebar.selectbox(
    "Ph∆∞∆°ng √°n x·ª≠ l√Ω N/A",
    ["Gi·ªØ nguy√™n (N/A)", "ƒêi·ªÅn gi√° tr·ªã g·∫ßn nh·∫•t (Forward Fill)", "ƒêi·ªÅn trung b√¨nh theo c·ªôt (Mean)"],
    index=0
)

if "ind_df_cache_d360" not in st.session_state:
    st.session_state["ind_df_cache_d360"] = pd.DataFrame()

if st.sidebar.button("üîç T√¨m ch·ªâ s·ªë"):
    with st.spinner("ƒêang t√¨m indicators t·ª´ Data360 (l·ªçc WB_WDI)‚Ä¶"):
        st.session_state["ind_df_cache_d360"] = data360_search_indicators(kw, top=40)

ind_df = st.session_state["ind_df_cache_d360"]

# Hi·ªÉn th·ªã B·∫¢NG K·∫æT QU·∫¢ T√åM: ID | T√™n ch·ªâ s·ªë
with st.sidebar.expander("K·∫øt qu·∫£ (ID | T√™n ch·ªâ s·ªë)", expanded=False):
    if ind_df.empty:
        st.info("Nh·∫•n **T√¨m ch·ªâ s·ªë** ƒë·ªÉ tra c·ª©u.")
    else:
        st.dataframe(ind_df[["ID","T√™n ch·ªâ s·ªë"]], use_container_width=True, height=260)

# Multiselect ch·ªçn theo "T√™n ‚Äî ID" ƒë·ªÉ r√µ r√†ng
if not ind_df.empty:
    display_options = [f"{r['T√™n ch·ªâ s·ªë']} ‚Äî {r['ID']}" for _, r in ind_df.iterrows()]
else:
    display_options = []

selected_display = st.sidebar.multiselect(
    "Ch·ªçn ch·ªâ s·ªë",
    options=display_options,
    default=display_options[:2] if display_options else []
)

# Mapping l·∫°i v·ªÅ ID v√† Name
id_list: List[str] = []
id_to_name: Dict[str, str] = {}
for disp in selected_display:
    if " ‚Äî " in disp:
        name, id_ = disp.split(" ‚Äî ", 1)
        id_list.append(id_)
        id_to_name[id_] = name

# ---------------- Tabs ----------------
tabs = st.tabs(["üìä D·ªØ li·ªáu","üìà Bi·ªÉu ƒë·ªì","üßÆ Th·ªëng k√™","üì• T·∫£i CSV","ü§ñ AI"])

# == TAB 1: D·ªÆ LI·ªÜU ==
with tabs[0]:
    st.subheader("D·ªØ li·ªáu (d·∫°ng r·ªông)")
    if st.button("üì• L·∫•y d·ªØ li·ªáu"):
        if not id_list:
            st.warning("Ch·ªçn √≠t nh·∫•t m·ªôt *ch·ªâ s·ªë*.")
            st.stop()

        all_long = []
        with st.spinner(f"T·∫£i {len(id_list)} ch·ªâ s·ªë cho {country_code}‚Ä¶"):
            for iid in id_list:
                df_fetch = wb_fetch_series(country_code, iid, int(y_from), int(y_to))
                if df_fetch is not None and not df_fetch.empty:
                    all_long.append(df_fetch)
                else:
                    # v·∫´n t·∫°o khung r·ªóng ƒë·ªÉ pivot ra ƒë·ªß c·ªôt
                    all_long.append(pd.DataFrame(columns=["Year","Country","IndicatorID","Value"]))
                time.sleep(0.25)

        df_long = pd.concat(all_long, ignore_index=True) if all_long else pd.DataFrame()

        # Pivot r·ªông + B·ªî SUNG ƒë·ªß c·ªôt theo danh s√°ch T√äN ƒë√£ ch·ªçn
        expected_names = [id_to_name[i] for i in id_list]
        df_wide = pivot_wide_with_missing(df_long, id_to_name, expected_names)

        # X·ª≠ l√Ω N/A theo tu·ª≥ ch·ªçn
        df_wide = handle_na(df_wide, na_method)

        st.session_state["wb_df_wide"] = df_wide
        st.success("‚úÖ ƒê√£ t·∫£i v√† chu·∫©n ho√° d·ªØ li·ªáu.")
        st.dataframe(df_wide.set_index("Year"), use_container_width=True)

def _get_df_wide():
    return st.session_state.get("wb_df_wide", pd.DataFrame())

# == TAB 2: BI·ªÇU ƒê·ªí ==
with tabs[1]:
    st.subheader("Bi·ªÉu ƒë·ªì")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i.")
    else:
        cols = [c for c in df.columns if c not in ("Year","Country")]
        choose = st.multiselect("Ch·ªçn c·ªôt v·∫Ω", options=cols, default=cols[:min(4, len(cols))])
        if choose:
            st.plotly_chart(px.line(df, x="Year", y=choose, color="Country", markers=True, title="Xu h∆∞·ªõng"), use_container_width=True)

            if len(choose) > 1:
                df_sel = df[choose].apply(pd.to_numeric, errors="coerce")
                df_sel = df_sel.dropna(axis=1, how="all")
                if df_sel.shape[1] >= 2:
                    corr = df_sel.corr().fillna(0)
                    hm = ff.create_annotated_heatmap(
                        z=corr.values,
                        x=corr.columns.tolist(),
                        y=corr.index.tolist(),
                        colorscale="Viridis",
                        annotation_text=corr.round(2).values,
                        showscale=True,
                    )
                    st.plotly_chart(hm, use_container_width=True)
                else:
                    st.info("C√°c c·ªôt ƒë∆∞·ª£c ch·ªçn kh√¥ng ƒë·ªß d·ªØ li·ªáu s·ªë ƒë·ªÉ t√≠nh t∆∞∆°ng quan.")

# == TAB 3: TH·ªêNG K√ä ==
with tabs[2]:
    st.subheader("Th·ªëng k√™ m√¥ t·∫£")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        cols = [c for c in df.columns if c not in ("Year","Country")]
        if not cols:
            st.info("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ th·ªëng k√™.")
        else:
            stats = df[cols].apply(pd.to_numeric, errors="coerce").describe().T
            stats["CV"] = (stats["std"]/stats["mean"]).abs()
            st.dataframe(
                stats[["mean","std","min","50%","max","CV"]]
                .rename(columns={"mean":"Mean","std":"Std","50%":"Median"}),
                use_container_width=True
            )

# == TAB 4: CSV ==
with tabs[3]:
    st.subheader("T·∫£i CSV")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        st.download_button(
            "üì• T·∫£i CSV",
            data=df.to_csv(index=False, encoding="utf-8-sig"),
            file_name=f"wb_{country_code}_{y_from}_{y_to}.csv",
            mime="text/csv"
        )

# == TAB 5: AI ==
with tabs[4]:
    st.subheader("AI insight (tu·ª≥ ch·ªçn)")
    df = _get_df_wide()
    if df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
    else:
        if genai is None or not os.environ.get("GOOGLE_API_KEY", ""):
            st.info("Ch∆∞a c·∫•u h√¨nh GOOGLE_API_KEY n√™n b·ªè qua AI insight.")
        else:
            try:
                genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
                model = genai.GenerativeModel("gemini-1.5-flash")
                data_string = df.to_csv(index=False)
                prompt = (
                    "B·∫°n l√† chuy√™n gia d·ªØ li·ªáu kinh t·∫ø. H√£y t√≥m t·∫Øt xu h∆∞·ªõng ch√≠nh, ƒëi·ªÉm b·∫•t th∆∞·ªùng, "
                    f"v√† g·ª£i √Ω 2‚Äì3 insight h√†nh ƒë·ªông cho qu·ªëc gia {selected_country_name} "
                    f"trong giai ƒëo·∫°n {y_from}-{y_to}. D·ªØ li·ªáu CSV:\n\n{data_string}\n\n"
                    "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·∫°ng bullet."
                )
                with st.spinner("AI ƒëang ph√¢n t√≠ch‚Ä¶"):
                    resp = model.generate_content(prompt)
                st.markdown(resp.text or "_Kh√¥ng c√≥ ph·∫£n h·ªìi_")
            except Exception as e:
                st.warning(f"AI l·ªói: {e}")
