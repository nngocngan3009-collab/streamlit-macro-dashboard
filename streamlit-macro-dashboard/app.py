# =========================
# Data360 (WB_WDI) Explorer ‚Äî Streamlit full app
# Gi·ªØ nguy√™n c√°c t√≠nh nƒÉng: b·∫£ng d·ªØ li·ªáu, CSV, pivot/heatmap, bi·ªÉu ƒë·ªì, AI insight
# Thay ph·∫ßn search & g·ªçi data theo y√™u c·∫ßu:
#   - Search: POST /data360/searchv2 (WB_WDI + type 'indicator')
#   - ID: full_id = WB_WDI_SP_POP_TOTL, pretty_id = SP.POP.TOTL
#   - Data: GET /data360/data?DATABASE_ID=WB_WDI&INDICATOR=<full_id>&[REF_AREA=...]
#   - H·ªó tr·ª£ ch·ªçn ALL indicators & ALL qu·ªëc gia
# =========================

import ssl, certifi
ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())

import os
import time
from typing import Dict, Any, List, Tuple, Optional
import streamlit as st
import pandas as pd
import requests
import plotly.express as px
import plotly.figure_factory as ff
import numpy as np

# (Tu·ª≥ ch·ªçn) AI insight v·ªõi Google Generative AI ‚Äî set GOOGLE_API_KEY n·∫øu mu·ªën d√πng
try:
    import google.generativeai as genai
except Exception:
    genai = None

# =========================
# Config
# =========================
DATA360_BASE_URL = os.environ.get("DATA360_BASE_URL", "https://api.data360.org")  # c·∫≠p nh·∫≠t theo m√¥i tr∆∞·ªùng c·ªßa b·∫°n
SEARCH_ENDPOINT  = "/data360/searchv2"
DATA_ENDPOINT    = "/data360/data"

HEADERS = {
    "Accept": "application/json",
    "Content-Type": "application/json",
}

REQ_TIMEOUT = 60
MAX_RETRIES = 4
BACKOFF     = 1.6

DEFAULT_DATE_RANGE = (2004, 2024)  # ch·ªâ ph·ª•c v·ª• filter/bi·ªÉu ƒë·ªì ph√≠a client (response v·∫´n l·∫•y ƒë·ªß)

# =========================
# HTTP Helpers (retry + backoff)
# =========================
def _retry_sleep(attempt: int, base: float = BACKOFF) -> float:
    return min(base ** attempt, 10.0)

def http_post_json(url: str, json_body: Dict[str, Any]):
    last_err = None
    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(url, json=json_body, headers=HEADERS, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_retry_sleep(attempt))
    raise RuntimeError(f"POST {url} failed after retries: {last_err}")

def http_get_json(url: str, params: Dict[str, Any]):
    last_err = None
    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.get(url, params=params, headers=HEADERS, timeout=REQ_TIMEOUT)
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.reason}", response=r)
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            time.sleep(_retry_sleep(attempt))
    raise RuntimeError(f"GET {url} failed after retries: {last_err}")

# =========================
# Search + ID helpers
# =========================
def cut_wb_id(full_id: str) -> str:
    # WB_WDI_SP_POP_TOTL -> SP_POP_TOTL
    return full_id[len("WB_WDI_"):] if full_id.startswith("WB_WDI_") else full_id

def to_pretty_id(full_id: str) -> str:
    # WB_WDI_SP_POP_TOTL -> SP.POP.TOTL
    return cut_wb_id(full_id).replace("_", ".")

@st.cache_data(show_spinner=False, ttl=600)
def search_indicators(keyword: str, top: int = 25) -> List[Dict[str, Any]]:
    """POST /data360/searchv2 ‚Äî l·ªçc WB_WDI + indicator; tr·∫£ list {full_id, pretty_id, name, database_id}"""
    url = f"{DATA360_BASE_URL}{SEARCH_ENDPOINT}"
    body = {
        "count": True,
        "select": "series_description/idno, series_description/name, series_description/database_id",
        "search": keyword,
        "top": int(top),
        "filter": "series_description/database_id eq 'WB_WDI' and type eq 'indicator'"
    }
    raw = http_post_json(url, body)

    # Chu·∫©n ho√° k·∫øt qu·∫£ (t√πy backend c√≥ th·ªÉ l√† 'value' ho·∫∑c 'items')
    rows = raw.get("value") or raw.get("items") or raw
    if isinstance(rows, dict):
        rows = rows.get("value") or rows.get("items") or []

    results = []
    for row in rows:
        idno = row.get("series_description/idno")
        name = row.get("series_description/name")
        dbid = row.get("series_description/database_id")

        if idno is None and isinstance(row.get("series_description"), dict):
            sd = row["series_description"]
            idno = sd.get("idno")
            name = name or sd.get("name")
            dbid = dbid or sd.get("database_id")

        if not idno:
            continue

        results.append({
            "full_id": idno,
            "pretty_id": to_pretty_id(idno),
            "name": name or idno,
            "database_id": dbid or "WB_WDI",
        })
    return results

# =========================
# Data fetch
# =========================
@st.cache_data(show_spinner=False, ttl=600)
def fetch_data(full_indicator_id: str, ref_area: Optional[str]) -> pd.DataFrame:
    """
    GET /data360/data?DATABASE_ID=WB_WDI&INDICATOR=<full>&[REF_AREA=...]
    - N·∫øu ref_area None ho·∫∑c 'ALL' -> kh√¥ng g·ª≠i REF_AREA
    Tr·∫£ DataFrame c√≥ c·ªôt chu·∫©n n·∫øu t√¨m th·∫•y: REF_AREA, TIME_PERIOD, VALUE, INDICATOR
    """
    url = f"{DATA360_BASE_URL}{DATA_ENDPOINT}"
    params = {"DATABASE_ID": "WB_WDI", "INDICATOR": full_indicator_id}
    if ref_area and ref_area.upper() != "ALL":
        params["REF_AREA"] = ref_area

    raw = http_get_json(url, params)

    # Chu·∫©n ho√°: th·ª≠ c√°c d·∫°ng response th√¥ng d·ª•ng
    if isinstance(raw, dict) and isinstance(raw.get("data"), list):
        rows = raw["data"]
    elif isinstance(raw, list):
        rows = raw
    else:
        rows = raw.get("value") or raw.get("items") or []

    df = pd.DataFrame(rows)

    # ƒêo√°n t√™n c·ªôt: (t√πy h·ªá th·ªëng Data360 c·ªßa b·∫°n‚Äîƒë·ªïi n·∫øu c·∫ßn)
    # ∆Øu ti√™n t√™n ph·ªï bi·∫øn:
    col_ref = next((c for c in df.columns if c.upper() in {"REF_AREA", "COUNTRY", "AREA", "LOCATION"}), None)
    col_time = next((c for c in df.columns if c.upper() in {"TIME_PERIOD", "TIME", "YEAR", "DATE"}), None)
    col_val = next((c for c in df.columns if c.upper() in {"VALUE", "OBS_VALUE", "VAL", "DATA"}), None)

    if df.empty:
        return df

    if col_ref is None or col_time is None or col_val is None:
        # N·∫øu kh√¥ng map ƒë∆∞·ª£c th√¨ c·ª© tr·∫£ raw + th√™m indicator cho c√≥ th√¥ng tin
        df["indicator"] = full_indicator_id
        return df

    df = df.rename(columns={col_ref: "REF_AREA", col_time: "TIME_PERIOD", col_val: "VALUE"})
    df["INDICATOR"] = full_indicator_id
    return df[["REF_AREA", "TIME_PERIOD", "VALUE", "INDICATOR"]]

def fetch_many(indicator_ids: List[str], ref_area: Optional[str]) -> pd.DataFrame:
    frames = []
    progress = st.progress(0.0, text="ƒêang t·∫£i d·ªØ li·ªáu‚Ä¶")
    total = len(indicator_ids) if indicator_ids else 1
    for i, iid in enumerate(indicator_ids, 1):
        try:
            df_i = fetch_data(iid, ref_area)
            if not df_i.empty:
                frames.append(df_i)
        except Exception as e:
            st.warning(f"L·ªói khi t·∫£i {iid}: {e}")
        progress.progress(i/total, text=f"ƒêang t·∫£i {i}/{total}")
    progress.empty()
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

# =========================
# Data utilities
# =========================
def handle_na(df: pd.DataFrame, method: str) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    if method == "Gi·ªØ nguy√™n (N/A)":
        return df
    if method == "ƒêi·ªÅn 0":
        return df.fillna(0)
    if method == "Forward-fill theo qu·ªëc gia + indicator":
        return df.sort_values(["REF_AREA","INDICATOR","TIME_PERIOD"]).groupby(["REF_AREA","INDICATOR"]).ffill()
    if method == "Backward-fill theo qu·ªëc gia + indicator":
        return df.sort_values(["REF_AREA","INDICATOR","TIME_PERIOD"]).groupby(["REF_AREA","INDICATOR"]).bfill()
    return df

def filter_year_range(df: pd.DataFrame, y_from: int, y_to: int) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    # TIME_PERIOD c√≥ th·ªÉ l√† s·ªë ho·∫∑c chu·ªói; c·ªë g·∫Øng √©p
    t = pd.to_numeric(df["TIME_PERIOD"], errors="coerce")
    mask = (t >= y_from) & (t <= y_to)
    return df.loc[mask].copy()

# =========================
# UI
# =========================
st.set_page_config(page_title="Data360 ‚Äî WB_WDI Explorer", layout="wide")
st.title("üîé Data360 ‚Äî WB_WDI Explorer")
st.caption("Gi·ªØ nguy√™n t√≠nh nƒÉng: b·∫£ng d·ªØ li·ªáu ‚Ä¢ CSV ‚Ä¢ pivot/heatmap ‚Ä¢ bi·ªÉu ƒë·ªì ‚Ä¢ AI insight.  Search/Data theo flow m·ªõi (Data360).")

# --- Search zone
with st.container():
    c1, c2, c3 = st.columns([3,1,1])
    with c1:
        keyword = st.text_input("T·ª´ kho√° indicator (v√≠ d·ª•: GDP, poverty‚Ä¶)", value="")
    with c2:
        top_n = st.number_input("Top k·∫øt qu·∫£", 1, 200, 25, 1)
    with c3:
        search_clicked = st.button("üîç T√¨m indicator (WB_WDI)")

search_results: List[Dict[str, Any]] = []
if search_clicked:
    if not keyword.strip():
        st.warning("Vui l√≤ng nh·∫≠p t·ª´ kho√°.")
    else:
        with st.spinner("ƒêang t√¨m indicator‚Ä¶"):
            search_results = search_indicators(keyword.strip(), int(top_n))
        if not search_results:
            st.info("Kh√¥ng t√¨m th·∫•y indicator ph√π h·ª£p.")

if search_results:
    st.subheader("K·∫øt qu·∫£ indicator")
    st.dataframe(pd.DataFrame([{
        "Indicator name": r["name"],
        "WB_ID (full)": r["full_id"],
        "WB_ID (pretty)": r["pretty_id"]
    } for r in search_results]), use_container_width=True, hide_index=True)

    st.markdown("**Ch·ªçn indicator** (h·ªó tr·ª£ **ALL**)")

    options = ["ALL"] + [f'{r["name"]} ‚Äî {r["pretty_id"]}' for r in search_results]
    picked = st.multiselect("Indicators", options, default=["ALL"])

    if "ALL" in picked:
        chosen_full_ids = [r["full_id"] for r in search_results]
    else:
        lookup = {f'{r["name"]} ‚Äî {r["pretty_id"]}': r["full_id"] for r in search_results}
        chosen_full_ids = [lookup[x] for x in picked if x in lookup]

    st.markdown("---")

    # Qu·ªëc gia: ALL ho·∫∑c m√£ ƒë∆°n/ƒëa (ph√¢n t√°ch b·∫±ng d·∫•u ph·∫©y -> s·∫Ω l·∫∑p fetch t·ª´ng m√£)
    st.subheader("Qu·ªëc gia / Khu v·ª±c (REF_AREA)")
    st.caption("Nh·∫≠p **ALL** ƒë·ªÉ l·∫•y to√†n b·ªô; ho·∫∑c nh·∫≠p 1 hay nhi·ªÅu m√£ (VD: VNM,USA,FRA).")
    ref_area_raw = st.text_input("REF_AREA", value="ALL")

    y_from, y_to = DEFAULT_DATE_RANGE
    y_from, y_to = st.slider("Kho·∫£ng nƒÉm (l·ªçc hi·ªÉn th·ªã, kh√¥ng ·∫£nh h∆∞·ªüng request)", min_value=1960, max_value=2025, value=(y_from, y_to))

    na_method = st.selectbox("X·ª≠ l√Ω N/A", ["Gi·ªØ nguy√™n (N/A)", "ƒêi·ªÅn 0", "Forward-fill theo qu·ªëc gia + indicator", "Backward-fill theo qu·ªëc gia + indicator"])

    tabs = st.tabs(["D·ªØ li·ªáu", "Pivot & Heatmap", "Bi·ªÉu ƒë·ªì", "AI insight"])

    # === Tab 1: D·ªØ li·ªáu ===
    with tabs[0]:
        if st.button("üì• L·∫•y d·ªØ li·ªáu"):
            if not chosen_full_ids:
                st.warning("Ch·ªçn √≠t nh·∫•t 1 indicator (ho·∫∑c ALL).")
                st.stop()

            ref_tokens = [x.strip() for x in ref_area_raw.split(",") if x.strip()] if ref_area_raw.strip().upper() != "ALL" else ["ALL"]

            frames = []
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu‚Ä¶"):
                for ref in ref_tokens:
                    if len(chosen_full_ids) == 1:
                        frames.append(fetch_data(chosen_full_ids[0], ref))
                    else:
                        frames.append(fetch_many(chosen_full_ids, ref))

            df = pd.concat([f for f in frames if f is not None and not f.empty], ignore_index=True) if frames else pd.DataFrame()
            if df is None or df.empty:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
                st.stop()

            # L·ªçc theo nƒÉm ph√≠a client
            df = filter_year_range(df, y_from, y_to)

            # X·ª≠ l√Ω N/A
            df = handle_na(df, na_method)

            st.success(f"S·ªë d√≤ng: {len(df)}")
            st.dataframe(df, use_container_width=True)

            # CSV
            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button("üíæ T·∫£i CSV", data=csv, file_name="data360_wb_wdi.csv", mime="text/csv")

            # L∆∞u t·∫°m v√†o session state cho tab kh√°c d√πng
            st.session_state["last_df"] = df

    # === Tab 2: Pivot & Heatmap ===
    with tabs[1]:
        df: pd.DataFrame = st.session_state.get("last_df")
        if df is None or df.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i tr∆∞·ªõc.")
        else:
            idx_cols = st.multiselect("Ch·ªçn ch·ªâ m·ª•c (index) cho pivot", ["REF_AREA", "INDICATOR", "TIME_PERIOD"], default=["REF_AREA", "TIME_PERIOD"])
            val_agg = st.selectbox("H√†m t·ªïng h·ª£p", ["mean", "sum", "min", "max", "median"], index=0)

            try:
                pt = pd.pivot_table(df, index=idx_cols, values="VALUE", aggfunc=val_agg)
                st.dataframe(pt, use_container_width=True)

                # N·∫øu pivot th√†nh d·∫°ng REF_AREA x TIME_PERIOD -> heatmap
                if set(idx_cols) == {"REF_AREA", "TIME_PERIOD"}:
                    mat = pt.reset_index().pivot(index="REF_AREA", columns="TIME_PERIOD", values="VALUE")
                    fig = ff.create_annotated_heatmap(
                        z=np.array(mat.values, dtype=float),
                        x=[str(x) for x in mat.columns],
                        y=list(mat.index),
                        showscale=True
                    )
                    st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"Kh√¥ng t·∫°o ƒë∆∞·ª£c pivot: {e}")

    # === Tab 3: Bi·ªÉu ƒë·ªì ===
    with tabs[2]:
        df: pd.DataFrame = st.session_state.get("last_df")
        if df is None or df.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i tr∆∞·ªõc.")
        else:
            # Line chart theo th·ªùi gian, ph√¢n t√°ch theo REF_AREA/INDICATOR
            hue = st.selectbox("T√¥ m√†u theo", options=["REF_AREA", "INDICATOR"], index=0)
            try:
                fig = px.line(df.sort_values("TIME_PERIOD"), x="TIME_PERIOD", y="VALUE", color=hue, markers=True)
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"Kh√¥ng v·∫Ω ƒë∆∞·ª£c bi·ªÉu ƒë·ªì: {e}")

    # === Tab 4: AI insight ===
    with tabs[3]:
        df: pd.DataFrame = st.session_state.get("last_df")
        if df is None or df.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. V√†o tab **D·ªØ li·ªáu** ƒë·ªÉ t·∫£i tr∆∞·ªõc.")
        else:
            st.caption("T√≥m t·∫Øt nhanh b·∫±ng AI (n·∫øu c√≥ GOOGLE_API_KEY).")
            if genai is None or not os.environ.get("GOOGLE_API_KEY"):
                st.info("Ch∆∞a c·∫•u h√¨nh GOOGLE_API_KEY ‚Äî b·ªè qua AI insight.")
            else:
                try:
                    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
                    model = genai.GenerativeModel("gemini-1.5-flash")
                    # Gi·ªõi h·∫°n d·ªØ li·ªáu ƒë∆∞a v√†o prompt ƒë·ªÉ nhanh
                    sample = df.head(100).to_dict(orient="records")
                    prompt = (
                        "B·∫°n l√† chuy√™n gia d·ªØ li·ªáu. H√£y ph√¢n t√≠ch xu h∆∞·ªõng ch√≠nh, ƒëi·ªÉm b·∫•t th∆∞·ªùng, "
                        "so s√°nh nhanh gi·ªØa qu·ªëc gia & ch·ªâ s·ªë trong d·ªØ li·ªáu WB_WDI d∆∞·ªõi ƒë√¢y. "
                        "ƒê·ªÅ xu·∫•t 2-3 insight h√†nh ƒë·ªông.\n\n"
                        f"D·ªØ li·ªáu m·∫´u (100 d√≤ng): {sample}"
                    )
                    resp = model.generate_content(prompt)
                    st.markdown(resp.text or "_Kh√¥ng c√≥ ph·∫£n h·ªìi_")
                except Exception as e:
                    st.warning(f"AI insight l·ªói: {e}")
